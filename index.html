<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="x-ua-compatible" content="ie=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Typist</title>
    <style>
      body {
        max-width: 640;
        margin: 0 auto;
        background-image: url("https://stmed.net/sites/default/files/wallpaper-wallpapers-25347-2123783.jpg");
      }

      .typist-transcript {
        position: fixed;
        left: 0;
        top: 0;
        bottom: 0;
        width: 35%;
        min-width: 100px;
        max-width: 500px;
        background-color: rgba(22, 38, 55, 0.8);
        color: white;
        padding: 15px;
        z-index: 9999;
        overflow-y: auto;
      }

      .typist-transcript > div {
        border-radius: 0 5px 5px;
        margin-bottom: 5px;
        padding: 3px;
        background-color: rgba(22, 38, 55, 0.8);
      }

      .typist-transcript > div > span {
        color: #4c9aff;
        display: block;
      }
    </style>
  </head>
  <body>
    <main class="typist-transcript"></main>
    <script type="application/javascript">
      function findLastTranscript(containerDomElem, userId) {
        if (!containerDomElem) {
          return null;
        }

        const children = containerDomElem.children || [];
        for (let i = children.length - 1; i >= 0; i -= 1) {
          const child = children[i];
          const childUserId = child.getAttribute("userId");
          if (childUserId === userId) {
            return child;
          }
        }

        return null;
      }

      function addTranscript(containerDomElem, result) {
        if (
          containerDomElem &&
          result &&
          result.text &&
          (result.isFinal || result.stability > 0.05)
        ) {
          let last = findLastTranscript(containerDomElem, result.id);
          let lastIsFinal =
            last && last.className && last.className.indexOf("final") >= 0;

          const newElement = !last || lastIsFinal;
          if (newElement) {
            last = document.createElement("div");
            last.setAttribute("userId", result.id || "");
            containerDomElem.appendChild(last);
            lastIsFinal = false;
          }

          last.innerHTML = `${
            result.name ? `<span>${result.name}</span>` : ""
          }${result.text}`;
          last.scrollIntoView &&
            last.scrollIntoView({ behavior: "smooth", block: "end" });
          if (result.isFinal) {
            last.className = "final";
          }
        }
      }

      function addTranscripts(containerDomElem, results) {
        if (containerDomElem && results && results.length) {
          let lastNotFinal = null;
          for (let i = 0; i < results.length; i += 1) {
            const result = results[i];
            if (!result.isFinal) {
              lastNotFinal = result;
            } else {
              addTranscript(containerDomElem, result);
              lastNotFinal = null;
            }
          }

          if (lastNotFinal) {
            addTranscript(containerDomElem, lastNotFinal);
          }
        }
      }

      const transcriptContainer = document.querySelector("main");

      const WebSocket = window.WebSocket || window.MozWebSocket;

      function createWebSocket() {
        const connection = new WebSocket("ws://localhost:1337");

        connection.onopen = function() {
          console.log("onopen");
        };

        connection.onerror = function(error) {
          console.log("onerror", error);
        };

        connection.onmessage = function(message) {
          // console.log("onmessage", message);

          try {
            var json = JSON.parse(message.data);
            console.log(json);
            addTranscript(transcriptContainer, json);
          } catch (e) {
            console.log("This doesn't look like a valid JSON: ", message.data);
            return;
          }
        };

        return connection;
      }

      let socket = createWebSocket();

      const AudioContext = window.AudioContext || window.webkitAudioContext;

      function getAudioStream() {
        return navigator.mediaDevices.getUserMedia({
          audio: {
            mandatory: {
              googEchoCancellation: "false",
              googAutoGainControl: "false",
              googNoiseSuppression: "false",
              googHighpassFilter: "false"
            }
          }
        });
      }

      function startRecording(stream) {
        const audioContext = new AudioContext();
        if (!audioContext) {
          return;
        }

        const inputPoint = audioContext.createGain();
        const microphone = audioContext.createMediaStreamSource(stream);
        const analyser = audioContext.createAnalyser();
        const scriptProcessor = inputPoint.context.createScriptProcessor(
          2048,
          2,
          2
        );

        microphone.connect(inputPoint);
        inputPoint.connect(analyser);
        inputPoint.connect(scriptProcessor);
        scriptProcessor.connect(inputPoint.context.destination);
        // This is for registering to the “data” event of audio stream, without overwriting the default scriptProcessor.onAudioProcess function if there is one.
        scriptProcessor.addEventListener("audioprocess", onStreamAudioData);
      }

      const ConversionFactor = 2 ** (16 - 1) - 1; // 32767
      const onStreamAudioData = e => {
        const floatSamples = e.inputBuffer.getChannelData(0);
        if (socket && socket.readyState === socket.OPEN) {
          const intSamples = Int16Array.from(
            floatSamples.map(n => n * ConversionFactor)
          );
          socket.send(intSamples);
        }
      };

      async function main() {
        const stream = await getAudioStream();
        startRecording(stream);
      }

      main();
    </script>
  </body>
</html>
